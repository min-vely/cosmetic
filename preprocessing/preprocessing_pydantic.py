import os
import json
from dotenv import load_dotenv
from typing import List
from langchain_openai import ChatOpenAI
from langchain.prompts import ChatPromptTemplate
from langchain.output_parsers import PydanticOutputParser
from pydantic import BaseModel, Field

# âœ… .env íŒŒì¼ì—ì„œ OPENAI_API_KEY ë¶ˆëŸ¬ì˜¤ê¸°
load_dotenv()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

# -----------------------------
# Pydantic ëª¨ë¸ ì •ì˜
# -----------------------------
class Product(BaseModel):
    brand_name: str = Field(..., description="ë¸Œëžœë“œëª…")
    product_name: str = Field(..., description="ì „ì²˜ë¦¬ëœ ì œí’ˆëª…")
    code_name: str = Field(..., description="ì „ì²˜ë¦¬ëœ ì½”ë“œëª…")
    price: str = Field(..., description="ê°€ê²© (ë¬¸ìžì—´)")
    product_main_image: str = Field(..., description="ëŒ€í‘œ ì´ë¯¸ì§€ URL")
    product_url: str = Field(..., description="ìƒí’ˆ ìƒì„¸ íŽ˜ì´ì§€ URL")

class Products(BaseModel):
    products: List[Product]

# -----------------------------
# LLM + Parser ì„¤ì •
# -----------------------------
parser = PydanticOutputParser(pydantic_object=Products)

prompt_template = ChatPromptTemplate.from_messages([
    ("system", 
     "ë„ˆëŠ” í™”ìž¥í’ˆ ì‡¼í•‘ëª° í¬ë¡¤ë§ ë°ì´í„°ë¥¼ ì „ì²˜ë¦¬í•˜ëŠ” ë„ìš°ë¯¸ì•¼. "
     "ì œí’ˆëª…ê³¼ ì½”ë“œëª…ì—ì„œ ë¸Œëžœë“œëª…, ìˆœìˆ˜ ì œí’ˆëª…ë§Œ ë‚¨ê¸°ê³ , "
     "ìš©ëŸ‰, ìƒ‰ìƒ, ë‹¨í’ˆ/ì„¸íŠ¸/ê¸°íš, (í’ˆì ˆ) ë“± ë¶ˆí•„ìš”í•œ ë‹¨ì–´ëŠ” ì œê±°í•´."),
    ("human", 
     "ë‹¤ìŒ ë°ì´í„°ë¥¼ ì „ì²˜ë¦¬í•´ì„œ JSON í˜•ì‹ìœ¼ë¡œ ì¶œë ¥í•´ì¤˜:\n\n{input}\n\n"
     "{format_instructions}")
])

llm = ChatOpenAI(
    temperature=0,
    model_name="gpt-4o",  # í•„ìš” ì‹œ gpt-4o, gpt-4o-mini ë“± ë³€ê²½ ê°€ëŠ¥
    openai_api_key=OPENAI_API_KEY,
)

# -----------------------------
# ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
# -----------------------------
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
INPUT_PATH = os.path.join(BASE_DIR, "..", "data", "oliveyoung_lip_makeup.json")
OUTPUT_PATH = os.path.join(BASE_DIR, "..", "data", "oliveyoung_lip_makeup_pydantic.json")

with open(INPUT_PATH, "r", encoding="utf-8") as f:
    data = json.load(f)

# -----------------------------
# ë°°ì¹˜ ì²˜ë¦¬
# -----------------------------
BATCH_SIZE = 20  # ìž…ë ¥ í¬ê¸° ì œí•œ ë•Œë¬¸ì— ë°°ì¹˜ ë‹¨ìœ„ë¡œ ì‹¤í–‰
results = []

for i in range(0, len(data), BATCH_SIZE):
    batch = data[i:i+BATCH_SIZE]
    input_str = json.dumps(batch, ensure_ascii=False, indent=2)

    prompt = prompt_template.format_messages(
        input=input_str,
        format_instructions=parser.get_format_instructions()
    )

    response = llm.invoke(prompt)
    parsed = parser.parse(response.content)

    results.extend(parsed.products)
    print(f"âœ… {i+len(batch)}ê°œ ì²˜ë¦¬ ì™„ë£Œ")

# -----------------------------
# ê²°ê³¼ ì €ìž¥
# -----------------------------
with open(OUTPUT_PATH, "w", encoding="utf-8") as f:
    json.dump({"products": [p.dict() for p in results]}, f, ensure_ascii=False, indent=2)

print(f"ðŸŽ‰ ì „ì²´ {len(results)}ê±´ ì €ìž¥ ì™„ë£Œ -> {OUTPUT_PATH}")
